# LASER_PCA_AncestryInference

**LASER_PCA_AncestryInference** is a modular [Nextflow DSL2](https://www.nextflow.io/) pipeline that performs **ancestry inference via principal component analysis (PCA)** using the [LASER software](https://genome.sph.umich.edu/wiki/LASER).  
It automates all steps required to project study samples onto a reference panel (HGDP + 1000 Genomes) while ensuring consistency across chromosomes and batches.

---

## üß¨ Pipeline overview

The pipeline performs the following key steps:

1. **Reference VCF normalization and filtering**
   - Split multi-allelic sites and normalize REF/ALT alleles.
   - Keep only bi-allelic, PASS variants within 0.05 < AF < 0.95.
   - Remove low-complexity and MHC regions.

2. **Study VCF normalization and filtering**
   - Apply the same variant-level filters and normalization.
   - Restrict to shared variants with the reference panel.

3. **Variant pruning**
   - Use `plink` to LD-prune high-quality common variants for PCA computation.

4. **LASER PCA on the reference panel**
   - Convert the filtered VCFs into LASER‚Äêcompatible `geno` and `site` files.
   - Compute the reference PCA coordinates (`RefPC.coord`).

5. **Batch-wise projection of study samples**
   - Split study samples into manageable batches (default = 1000).
   - For each batch, run LASER to project samples onto the reference PCA space.

6. **Merging and visualization**
   - Concatenate all projected batches into a unified `final.ProPC.coord`.
   - Plot the reference + projected samples using the `bin/PCA.R` script.

---

## üìÇ Repository structure

LASER_PCA_AncestryInference/
|-- main.nf                  # Main Nextflow pipeline
|-- nextflow.config          # Global configuration file
|-- bin/
|   `-- PCA.R                # R script for PCA visualization
|-- scripts/
|   `-- launch_da.sh         # SLURM launcher for Digital Alliance
|-- conf/                    # (Optional) future config profiles
|-- README.md
|-- .gitignore
`-- LICENSE


> The `bin/` directory is automatically added to the `$PATH` by Nextflow, so scripts inside it (like `PCA.R`) can be called directly within processes.



---

## üì• Inputs

All input paths are defined in `nextflow.config`.

| Input file | Description |
|-------------|--------------|
| `params.input_reference` | Glob for per-chromosome **reference VCFs** (`chr*.vcf.gz` + `.tbi`) |
| `params.input_study` | Glob for per-chromosome **study VCFs** (`chr*.vcf.gz` + `.tbi`) |
| `params.qc_ref_list` | List of reference sample IDs (one per line) |
| `params.qc_study_list` | List of study sample IDs (one per line) |
| `params.lowcomplexity_bed` | BED file listing low-complexity regions and MHC to exclude |
| `params.header_bed` | `"TRUE"` if the BED has a header line |
| `params.meta_file` | Metadata table with sample and population info for plotting |
| `params.ref_fasta` | hg38 reference FASTA (used for normalization) |
| `params.path_to_laser` | Path to directory containing LASER binaries (`laser`, `vcf2geno`) |

---

## üì§ Outputs

Results are organized under `results/LASER_PCA/` (or your chosen `params.outdir`):

| Output | Description |
|---------|--------------|
| `reference_pruned.*` | Pruned and filtered reference data (VCF, LASER `geno` and `site`) |
| `reference.RefPC.coord` | PCA coordinates for the reference samples |
| `final.ProPC.coord` | Combined reference + projected study coordinates |
| `plot_PCA/` | PCA scatterplots generated by `bin/PCA.R` |
| `reports/` | HTML run reports and timelines (`-with-report`, `-with-timeline`) |
| `logs/` | SLURM output/error logs when launched via `launch_da.sh` |

Intermediate files are cached in `work/` and can be re-used with `-resume`.

---

## ‚öôÔ∏è Parameters

| Parameter | Description | Default / Example |
|------------|--------------|-------------------|
| `--input_reference` | Reference VCF glob | `path/to/ref/chr*.vcf.gz` |
| `--input_study` | Study VCF glob | `path/to/study/chr*.vcf.gz` |
| `--qc_ref_list` | Reference sample list | `lists/ref_samples.txt` |
| `--qc_study_list` | Study sample list | `lists/study_samples.txt` |
| `--lowcomplexity_bed` | BED of excluded regions | `bed/gaps_telomeres_mhc.bed` |
| `--header_bed` | Whether BED has header | `"TRUE"` |
| `--meta_file` | Metadata file for plotting | `meta/ref_metadata.tsv` |
| `--ref_fasta` | Reference FASTA | `ref/hg38.fa` |
| `--path_to_laser` | Directory containing LASER binaries | `/path/to/LASER/` |
| `--nPCs` | Number of principal components | `20` |
| `--k` | LASER `-k` value (PCs to project on) | `20` |
| `--batch_size` | Samples per projection batch | `1000` |
| `--seed` | Random seed for reproducibility | `11` |
| `--threshold_N` | Minimum samples per group for plotting | `10` |

---

## üß© Dependencies

- **Nextflow** (‚â• 22.10, DSL2)
- **Java 17**
- **bcftools**
- **plink 1.9**
- **LASER** binaries (`laser`, `vcf2geno`)
- **R ‚â• 4.2** with packages required by `bin/PCA.R`

### On Digital Alliance / Compute Canada
Load modules within your job script (`scripts/launch_da.sh`), for example:
```bash
module load nextflow
module load bcftools
module load plink/1.9
module load r/4.5.0
```




---

## üöÄ Usage examples

**A. Digital Alliance (SLURM)**

# Edit scripts/launch_da.sh with your account/time/mem/CPUs
```bash
bash scripts/launch_da.sh
```

This will automatically create logs/ and reports/ directories and run:
```bash
nextflow run . -c nextflow.config -resume \
  -with-report reports/<timestamp>_report.html \
  -with-timeline reports/<timestamp>_timeline.html
```

**B. Direct invocation (local or HPC shell)**
```bash
nextflow run . \
  -c nextflow.config \
  -resume \
  --nPCs 20 --k 20 --batch_size 1000 \
  --path_to_laser /path/to/LASER \
  --ref_fasta /path/to/hg38.fa \
  -with-report reports/run_report.html \
  -with-timeline reports/timeline.html
```
**C. Quick smoke test**
```bash
nextflow run . -stub-run -profile test
```



---

##  Notes & Conventions

- Chromosomes: expects autosomes (1‚Äì22) named chrN.
- Input VCFs: must be bgzipped (.vcf.gz) and indexed (.tbi).
- Variant IDs: handled consistently across datasets.
- bin folder: all scripts inside bin/ (e.g. PCA.R) are automatically added to $PATH.
- Intermediate data: stored in work/; reuse with -resume to skip completed steps.
- Parallelization: Nextflow automatically manages parallel chromosome processing and batch projections.



---

##  üìö Citation

If you use this pipeline, please cite:

Pelletier, J. (2025).
LASER_PCA_AncestryInference: A Nextflow pipeline for ancestry inference via PCA projection.
GitHub: https://github.com/JustinPelletier/LASER_PCA_AncestryInference



